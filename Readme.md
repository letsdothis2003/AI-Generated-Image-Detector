# Haven't thought of a creative name for this yet! 

During covid, I got interested into deepfakes or images manipulated by artificial intelligence as they looked uncanny. Around fall of 2025, this interest got further developed as I learned more about digital image processing and also
other security issues regarding ai-generated content. Me and my friedn Ahmed Ali have been creating a system to detect such stuff. 

## ðŸ“Œ Overview

This project explores how machine learning models learn to interpret images. The goal is to build a system that can detect and classify different types of visual data.

---




## ðŸš€ Phase 1 â€” MNIST Digit Recognition

The first phase uses MNIST dataset, a classic benchmark of  handwritten digits (0â€“9).

### Objectives
- Preprocess and normalize image data  
- Train a neural network to classify digits  
- Evaluate accuracy and performance until its like 90-ish percent. 


### Results
96 percent accuracy baby! 

---

## ðŸ”® Phase 2 â€” Face Detection (In Progress)

The next phase expands the project into peoples faces(we are considering animals as well), which introduces more complexity such as higher-resolution images, lighting variation, and facial feature differences.

### Planned Features
- Detect faces in static images  
- Explore real-time detection via webcam  
- Compare different model architectures  
- Build a unified interface supporting both digit and face detection



## ðŸ”® Phase 3 â€” Uncaniness Assessment(Future)

You know how Ai for some reason gives people extra fingers or weird skin textures, this is just that.

### Planned Features
- Use a non-Ai picture to assess an Ai generated one. 


